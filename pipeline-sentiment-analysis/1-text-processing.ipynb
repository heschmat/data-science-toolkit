{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artistic-moment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can download all packages by: nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "gothic-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "existing-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "hydraulic-membrane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adapted-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "inner-plymouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-constitution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "stylish-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_orig = 'My favorite fictional character is Dr. House; simply AMAZING. I miss the show!'\n",
    "text = text_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "similar-family",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my favorite fictional character is dr. house; simply amazing. i miss the show!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "synthetic-filling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my favorite fictional character is dr  house  simply amazing  i miss the show '"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace non-alpha-numeric with a space\n",
    "text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "mental-cancer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my favorite fictional character is dr house simply amazing i miss the show'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace tabs, multiple blanks with one single space\n",
    "text = re.sub('\\s+', ' ',text).strip()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cooked-carbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'is',\n",
       " 'dr',\n",
       " 'house',\n",
       " 'simply',\n",
       " 'amazing',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'show']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "graphic-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'is',\n",
       " 'dr',\n",
       " 'house',\n",
       " 'simply',\n",
       " 'amazing',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'show']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "verbal-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'is',\n",
       " 'dr.',\n",
       " 'house',\n",
       " ';',\n",
       " 'simply',\n",
       " 'amazing',\n",
       " '.',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'show',\n",
       " '!']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text_orig.lower()) # pay attention to 'dr.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "senior-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my favorite fictional character is dr. house; simply amazing.',\n",
       " 'i miss the show!']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text_orig.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-smith",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "accepted-sixth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "hungarian-three",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\tme\tmy\tmyself\twe\tour\tours\tourselves\tyou\tyou're\tyou've\tyou'll\tyou'd\tyour\tyours\tyourself\tyourselves\the\thim\this\thimself\tshe\tshe's\ther\thers\therself\tit\tit's\tits\titself\tthey\tthem\ttheir\ttheirs\tthemselves\twhat\twhich\twho\twhom\tthis\tthat\tthat'll\tthese\tthose\tam\tis\tare\twas\twere\tbe\tbeen\tbeing\thave\thas\thad\thaving\tdo\tdoes\tdid\tdoing\ta\tan\tthe\tand\tbut\tif\tor\tbecause\tas\tuntil\twhile\tof\tat\tby\tfor\twith\tabout\tagainst\tbetween\tinto\tthrough\tduring\tbefore\tafter\tabove\tbelow\tto\tfrom\tup\tdown\tin\tout\ton\toff\tover\tunder\tagain\tfurther\tthen\tonce\there\tthere\twhen\twhere\twhy\thow\tall\tany\tboth\teach\tfew\tmore\tmost\tother\tsome\tsuch\tno\tnor\tnot\tonly\town\tsame\tso\tthan\ttoo\tvery\ts\tt\tcan\twill\tjust\tdon\tdon't\tshould\tshould've\tnow\td\tll\tm\to\tre\tve\ty\tain\taren\taren't\tcouldn\tcouldn't\tdidn\tdidn't\tdoesn\tdoesn't\thadn\thadn't\thasn\thasn't\thaven\thaven't\tisn\tisn't\tma\tmightn\tmightn't\tmustn\tmustn't\tneedn\tneedn't\tshan\tshan't\tshouldn\tshouldn't\twasn\twasn't\tweren\tweren't\twon\twon't\twouldn\twouldn't\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "hired-population",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'is',\n",
       " 'dr',\n",
       " 'house',\n",
       " 'simply',\n",
       " 'amazing',\n",
       " 'i',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'show']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text_orig.lower()\n",
    "\n",
    "text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "words = word_tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "norwegian-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['favorite',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'dr',\n",
       " 'house',\n",
       " 'simply',\n",
       " 'amazing',\n",
       " 'miss',\n",
       " 'show']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for word in words if word not in stopwords.words('english')]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eight-resort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['favorit',\n",
       " 'fiction',\n",
       " 'charact',\n",
       " 'dr',\n",
       " 'hous',\n",
       " 'simpli',\n",
       " 'amaz',\n",
       " 'miss',\n",
       " 'show']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[PorterStemmer().stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "hundred-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['walk', 'walk', 'walker']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[PorterStemmer().stem(word) for word in ['walking', 'walked', 'walker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "medieval-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bore', 'bore', 'bore']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[PorterStemmer().stem(word) for word in ['bored', 'boring', 'bore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fifteen-death",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['favorite',\n",
       " 'fictional',\n",
       " 'character',\n",
       " 'dr',\n",
       " 'house',\n",
       " 'simply',\n",
       " 'amazing',\n",
       " 'miss',\n",
       " 'show']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WordNetLemmatizer().lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "amino-pillow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['walking', 'walked', 'walker']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WordNetLemmatizer().lemmatize(word) for word in ['walking', 'walked', 'walker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "hollow-virginia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bored', 'boring', 'bore']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WordNetLemmatizer().lemmatize(word) for word in ['bored', 'boring', 'bore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "proved-suspension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'is', 'ha', 'have', 'go', 'persuades']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WordNetLemmatizer().lemmatize(word) for word in ['am', 'is', 'has', 'have', 'goes', 'persuades']] # has => ha ;))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "greater-worth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'be', 'have', 'have', 'go', 'persuade', 'tree']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WordNetLemmatizer().lemmatize(word, pos= 'v') for word in ['am', 'is', 'has', 'have', 'goes', 'persuades', 'trees']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-dance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "frozen-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'is', 'ha', 'have', 'goe', 'persuad', 'tree']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[PorterStemmer().stem(word) for word in ['am', 'is', 'has', 'have', 'goes', 'persuades', 'trees']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-niagara",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "central-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('always', 'RB'),\n",
       " ('lie', 'VBP'),\n",
       " ('down', 'RP'),\n",
       " ('to', 'TO'),\n",
       " ('tell', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('lie', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize('I always lie down to tell a lie.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-riding",
   "metadata": {},
   "source": [
    "There are other more advanced forms of POS tagging that can learn sentence structures and tags from given data, including __Hidden Markov Models (HMMs)__ and __Recurrent Neural Networks (RNNs)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "functioning-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m                     [\n\u001b[1;32m--> 798\u001b[1;33m                         find_binary(\n\u001b[0m\u001b[0;32m    799\u001b[0m                             \u001b[1;34m\"gs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    687\u001b[0m ):\n\u001b[1;32m--> 688\u001b[1;33m     return next(\n\u001b[0m\u001b[0;32m    689\u001b[0m         find_binary_iter(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m     for file in find_file_iter(\n\u001b[0m\u001b[0;32m    674\u001b[0m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"=\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n%s\\n%s\\n%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 )\n\u001b[0;32m    816\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Lucy', 'NNP')]), ('joined', 'VBD'), Tree('ORGANIZATION', [('Udacity', 'NNP'), ('Inc.', 'NNP')]), ('in', 'IN'), Tree('GPE', [('California', 'NNP')]), ('.', '.')])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_chunk(pos_tag(word_tokenize('Lucy joined Udacity Inc. in California.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-therapist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
