{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "funded-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "recent-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Heschmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "greek-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "guided-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-empire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "adequate-disposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>category</th>\n",
       "      <th>category:confidence</th>\n",
       "      <th>category_gold</th>\n",
       "      <th>id</th>\n",
       "      <th>screenname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662822308</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/18/15 4:31</td>\n",
       "      <td>Information</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.365280e+17</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Barclays CEO stresses the importance of regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>662822309</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/18/15 13:55</td>\n",
       "      <td>Information</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.860130e+17</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Barclays announces result of Rights Issue http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>662822310</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/18/15 8:43</td>\n",
       "      <td>Information</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.795800e+17</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Barclays publishes its prospectus for its å£5....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  662822308    False   finalized                   3      2/18/15 4:31   \n",
       "1  662822309    False   finalized                   3     2/18/15 13:55   \n",
       "2  662822310    False   finalized                   3      2/18/15 8:43   \n",
       "\n",
       "      category  category:confidence category_gold            id screenname  \\\n",
       "0  Information                  1.0           NaN  4.365280e+17   Barclays   \n",
       "1  Information                  1.0           NaN  3.860130e+17   Barclays   \n",
       "2  Information                  1.0           NaN  3.795800e+17   Barclays   \n",
       "\n",
       "                                                text  \n",
       "0  Barclays CEO stresses the importance of regula...  \n",
       "1  Barclays announces result of Rights Issue http...  \n",
       "2  Barclays publishes its prospectus for its å£5....  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "technical-marking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Information    2129\n",
       "Action          724\n",
       "Dialogue        226\n",
       "Exclude          39\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "united-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000    2430\n",
       "0.6614      35\n",
       "0.6643      33\n",
       "0.6747      32\n",
       "0.6775      29\n",
       "          ... \n",
       "0.7202       1\n",
       "0.8860       1\n",
       "0.8570       1\n",
       "0.6568       1\n",
       "0.9041       1\n",
       "Name: category:confidence, Length: 194, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category:confidence'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-header",
   "metadata": {},
   "source": [
    "Only keep the rows with `confidence` of 100%. Also, remove the `category` of `Exclude`, as there are very few of them anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-green",
   "metadata": {},
   "source": [
    "## 0. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "catholic-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "    df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "    X = df.text.values\n",
    "    y = df.category.values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "tutorial-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "spoken-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barclays CEO stresses the importance of regulatory and cultural reform in financial services at Brussels conference  http://t.co/Ge9Lp7hpyG'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "broad-military",
   "metadata": {},
   "source": [
    "### 1. Clean & Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-capacity",
   "metadata": {},
   "source": [
    "Replace the urls in the messages with `urlplaceholder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "entertaining-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegEx for url pattern\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "greater-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barclays CEO stresses the importance of regulatory and cultural reform in financial services at Brussels conference  http://t.co/Ge9Lp7hpyG'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = X[0]\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "responsible-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://t.co/Ge9Lp7hpyG']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(url_regex, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "express-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barclays CEO stresses the importance of regulatory and cultural reform in financial services at Brussels conference  urlplaceholder'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://t.co/Ge9Lp7hpyG'\n",
    "msg.replace(url, 'urlplaceholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "exciting-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    # get list of all urls using regex\n",
    "    detected_urls = re.findall(url_regex, txt)\n",
    "    \n",
    "    # replace each url in text string with placeholder\n",
    "    for url in detected_urls:\n",
    "        txt = txt.replace(url, 'urlplaceholder')\n",
    "\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(txt.lower())\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer\n",
    "    # Lemmatize and remove the white spaces - leading & trailing\n",
    "    tokens_clean = [lemmatizer().lemmatize(token.strip()) for token in tokens]\n",
    "\n",
    "    return tokens_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "pregnant-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barclays CEO stresses the importance of regulatory and cultural reform in financial services at Brussels conference  http://t.co/Ge9Lp7hpyG\n",
      "=======>  ['barclays', 'ceo', 'stress', 'the', 'importance', 'of', 'regulatory', 'and', 'cultural', 'reform', 'in', 'financial', 'service', 'at', 'brussels', 'conference', 'urlplaceholder'] \n",
      "\n",
      "========================================================================\n",
      "Barclays announces result of Rights Issue http://t.co/LbIqqh3wwG\n",
      "=======>  ['barclays', 'announces', 'result', 'of', 'right', 'issue', 'urlplaceholder'] \n",
      "\n",
      "========================================================================\n",
      "Barclays publishes its prospectus for its å£5.8bn Rights Issue: http://t.co/YZk24iE8G6\n",
      "=======>  ['barclays', 'publishes', 'it', 'prospectus', 'for', 'it', 'å£5.8bn', 'right', 'issue', ':', 'urlplaceholder'] \n",
      "\n",
      "========================================================================\n",
      "Barclays Group Finance Director Chris Lucas is to step down at the end of the week due to ill health http://t.co/nkuHoAfnSD\n",
      "=======>  ['barclays', 'group', 'finance', 'director', 'chris', 'lucas', 'is', 'to', 'step', 'down', 'at', 'the', 'end', 'of', 'the', 'week', 'due', 'to', 'ill', 'health', 'urlplaceholder'] \n",
      "\n",
      "========================================================================\n",
      "Barclays announces that Irene McDermott Brown has been appointed as Group Human Resources Director http://t.co/c3fNGY6NMT\n",
      "=======>  ['barclays', 'announces', 'that', 'irene', 'mcdermott', 'brown', 'ha', 'been', 'appointed', 'a', 'group', 'human', 'resource', 'director', 'urlplaceholder'] \n",
      "\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# test out function\n",
    "X, y = load_data()\n",
    "for msg in X[:5]:\n",
    "    tokens = tokenize(msg)\n",
    "    print(msg)\n",
    "    print('=======> ', tokens, '\\n')\n",
    "    print('=' * 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-testament",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "verified-battle",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-holmes",
   "metadata": {},
   "source": [
    "### Step 1: Load data and perform a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "white-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = load_data()\n",
    "\n",
    "# perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-placement",
   "metadata": {},
   "source": [
    "### Step 2: Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "outstanding-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate transformers and classifier\n",
    "vect = CountVectorizer(tokenizer= tokenize)\n",
    "tfidf = TfidfTransformer()\n",
    "clf = RandomForestClassifier(random_state= 0)\n",
    "\n",
    "# Fit and/or transform each to the data\n",
    "X_train_counts = vect.fit_transform(X_train)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-maine",
   "metadata": {},
   "source": [
    "### Step 3: Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "structured-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "X_test_counts = vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "\n",
    "# Predict test labels\n",
    "y_test_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "raised-latvia",
   "metadata": {},
   "source": [
    "### Step 4: Display results\n",
    "Display a confusion matrix and accuracy score based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "metric-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "Confusion Matrix:\n",
      " [[ 85   0  34]\n",
      " [  2  31   6]\n",
      " [  3   2 438]]\n",
      "Accuracy: 0.922\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_test_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_test_pred, labels= labels)\n",
    "accuracy = (y_test == y_test_pred).mean().round(3)\n",
    "\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-enhancement",
   "metadata": {},
   "source": [
    "# Final Step: Refactor\n",
    "Organize these steps into the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "neither-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_test_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_test_pred, labels= labels)\n",
    "    accuracy = (y_test == y_test_pred).mean().round(3)\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "friendly-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_naive():\n",
    "    # load data\n",
    "    X, y = load_data()\n",
    "    # Split the data into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 6)\n",
    "    \n",
    "    # Instantiate transformers and classifier\n",
    "    vect = CountVectorizer(tokenizer= tokenize)\n",
    "    tfidf = TfidfTransformer()\n",
    "    clf = RandomForestClassifier(random_state= 0)\n",
    "\n",
    "    # Fit and/or transform each to the data\n",
    "    X_train_counts = vect.fit_transform(X_train)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Transform test data\n",
    "    X_test_counts = vect.transform(X_test)\n",
    "    X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "    # Predict test labels\n",
    "    y_test_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    display_results(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "developing-resistance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "Confusion Matrix:\n",
      " [[ 18   5  84]\n",
      " [  5   0  23]\n",
      " [ 67  28 371]]\n",
      "Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "main_naive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-receiver",
   "metadata": {},
   "source": [
    "### Advantages of Using Pipeline:   \n",
    "1. Simplicity and Convencience   \n",
    "2. Optimizing Entire Workflow, including data transformation and modeling steps. \n",
    "3. Preventing Data leakage   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-freight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "static-southwest",
   "metadata": {},
   "source": [
    "## 3. Implementing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bibliographic-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipe():\n",
    "    # Load the data\n",
    "    X, y = load_data()\n",
    "    # Split data into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 6)\n",
    "\n",
    "    # Build pipeline\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', RandomForestClassifier(random_state= 0))\n",
    "    ])\n",
    "        \n",
    "    # Train classifier\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Display results\n",
    "    display_results(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "catholic-asset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "Confusion Matrix:\n",
      " [[ 18   5  84]\n",
      " [  5   0  23]\n",
      " [ 67  28 371]]\n",
      "Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "main_pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-gallery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "developed-hungary",
   "metadata": {},
   "source": [
    "## 4. Pipelines And Feature Unions\n",
    "- A `pipeline` performs a list of steps in a _linear sequence_, while a `feature union` performs a list of steps in _parallel_ and then combines their results.\n",
    "- In more complex workflows, multiple feature unions are often used within pipelines, and multiple pipelines are used within feature unions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-fiber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
